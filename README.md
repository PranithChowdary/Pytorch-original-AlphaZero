# Pytorch-original-AlphaZero

My implementation of the original AlphaZero paper:  
**"A general reinforcement learning algorithm that masters Chess, Shogi, and Go through self-play"**  
â†’ [Silver et al., DeepMind, 2017](https://www.nature.com/articles/nature24270)


## ğŸš€ Overview

This project reimplements the core ideas of AlphaZero using PyTorch from scratch.  
It supports training and evaluation on board games like **Go** and **Gomoku**, with modular MCTS, a deep residual neural network, and a scalable self-play pipeline.  
Designed with **research reproducibility**, **educational clarity**, and **modular experimentation** in mind.


## ğŸ”¥ Key Features

- ğŸ§  **MCTS (v1 & v2)** â€” Custom implementations with tree reuse, visit counts, and exploration noise
- ğŸ—ï¸ **Neural Network** â€” Deep residual CNN with separate policy and value heads
- â™»ï¸ **Self-Play Training** â€” Built-in actor, learner, and replay loop
- ğŸ“Š **Evaluation Framework** â€” Elo rating, agent vs agent, and CrazyStone integration
- ğŸ“ˆ **TensorBoard Logging** â€” For real-time tracking of training metrics
- ğŸ³ **Docker Support** â€” Reproducible environment for fast deployment
- ğŸŒ **Notebook UI** â€” Play interactively against trained agents in-browser
- ğŸ” **SGF Support** â€” Replay and analyze Go games using Sabaki or similar tools


## ğŸ—‚ï¸ Project Structure

```

.
â”œâ”€â”€ alpha\_zero/             # Core logic (MCTS, model, pipeline)
â”‚   â”œâ”€â”€ core/                # MCTS, network, rating, replay
â”‚   â”œâ”€â”€ envs/                # Go & Gomoku environments (Gym-style)
â”‚   â””â”€â”€ utils/               # SGF parsing, data transformations, logging
â”œâ”€â”€ eval_play/               # GUI/CLI for evaluating trained agents
â”œâ”€â”€ logs/                    # TensorBoard and evaluation logs
â”œâ”€â”€ docker/                  # Dockerfile for reproducibility
â”œâ”€â”€ others/                  # Analysis scripts, Elo graphs, score systems
â”œâ”€â”€ unit_tests/              # Tests for environments, MCTS, transformations
â”œâ”€â”€ plot_go.py               # Training visualization
â”œâ”€â”€ plot_gomoku.py
â”œâ”€â”€ run_unit_tests.sh
â””â”€â”€ README.md

````


## âš™ï¸ Getting Started

### âœ… 1. Install with Docker (Recommended)

```bash
docker build -t alphazero-pytorch -f docker/Dockerfile .
docker run -it --rm -p 6006:6006 alphazero-pytorch
````

### âœ… 2. Or install manually

```bash
pip install -r requirements.txt
```


## ğŸ‹ï¸ Train an Agent

### Train Go (9x9 board):

```bash
python alpha_zero/training_go.py
```

### Train Gomoku (13x13 board):

```bash
python alpha_zero/training_gomoku.py
```

TensorBoard logs saved to `logs/`:

```bash
tensorboard --logdir logs/
```

## ğŸ§ª Evaluate Agents

### GUI/Terminal Match:

```bash
python eval_play/eval_agent_go.py                 # GUI
python eval_play/eval_agent_go_cmd.py             # Terminal
```

### Match against Crazystone (manual proxy):

```bash
python eval_play/eval_agent_go_cmd.py --opponent crazystone
```


## ğŸ® Play in Browser (Notebook)

Launch Jupyter and play interactively in-browser:

```bash
jupyter notebook notebooks/play_agent_demo.ipynb
```


## ğŸ“Š Visualize Progress

```bash
python plot_go.py        # Elo & Win-rate vs Checkpoints
python plot_gomoku.py
```

## ğŸ§  Research Notes

* Training is scaled-down for accessibility (fewer simulations, smaller nets)
* Designed to be **hackable**: plug in your own game, change architecture, modify MCTS
* All games stored in **SGF format** for compatibility with viewers like Sabaki


## ğŸ“Œ To-Do & Roadmap

* [ ] Add full Chess and Shogi support
* [ ] Integrate Prioritized Replay Buffer
* [ ] Distributed Self-Play with Ray or Dask
* [ ] Improved GUI (Streamlit / WebRTC)
* [ ] Support for AlphaZero variants (MuZero, EfficientZero)


## ğŸ“œ License

This project is licensed under the **MIT License**. See [LICENSE](./LICENSE) for full details.


## ğŸ™ Acknowledgments

* DeepMind for AlphaZero and GTP logic
* MiniGo, Leela Zero, and Sabaki for inspiration
* OpenAI Gym and PyTorch for frameworks


## ğŸ§  Author

**Pranith Chowdary Karumanchi**
Research-focused AI Engineer | ML + RL + LLMs
[GitHub](https://github.com/yourusername) â€¢ [LinkedIn](https://linkedin.com/in/yourprofile)


Feel free to â­ this repo if you find it useful!
